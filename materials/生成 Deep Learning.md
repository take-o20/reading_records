# 生成 Deep Learning

## 第Ⅰ部　生成ディープラーニング入門

### 1章 生成モデリング

* 識別モデリングと生成モデリングの違いが分かりやすかった
  * 対象の観測範囲（ドメイン）があるとする
    * 識別モデリングはある観測xが与えられたとき、それが観測範囲に属する確率をモデリングする
    ```
    「識別モデリング」は p(y|x)を推定する
    すなわち、識別モデリングは、ある観測xが与えられたとき、それがラベルyである確率をモデル化しようとします。
    ```
    * 生成モデリングはある観測xが与えられたとき、それの観測範囲をモデリングする
      * そのモデルした観測範囲からサンプリングすることで新しい観測を生成できる
    ```
    「生成モデリング」はp(x)を推定する
    すなわち、生成モデリングは、観測xが観測される確率をモデル化しようとします。この分布からサンプリングすることで、新しい観測を生成することができます。
    ```

### 2章 ディープラーニング

* ハンズオンの説明が記されていた、見覚えがあるような、ないような。
* 画像に何が写っているかを予測する多層パーセプトロンを構築する
* 畳み込み層、ドロップアウト層、バッチ正規化層を使用してモデルの性能を向上させる
* 多層パーセプトロン（MLP）
  * 識別モデリングの一つ
  * 教師あり学習
    * 機械学習アルゴリズムの一種
    * コンピュータをラベル付きデータセットで訓練する
* 畳み込み層
  * 畳み込みニューラルネットワーク
  * フィルタの集まり
    * 入力のデータに複数の領域を定義し、それぞれの領域に対しフィルターを適用する。適用した結果の出力は「本来あったいくつかの要素を領域で畳み込んだもの」となる。
  * ネットワークの特徴量を抽出することができる
    * より精度の高いネットワークを作成できる
* ドロップアウト層
  * 各層で確率的な割合でニューロンの出力を0にする
    * 過学習を避けられる
* バッチ正規化層
  * 勾配爆発を避ける
  * 重みが大きくなりすぎる
  * 詳しくはp53の数式を参照

## 第Ⅱ部　手法

### 変分オートエンコーダ

* ワードロープを用いた例
  * 服を似たもの同士でワードロープに保管する
    * 保管場所は座標で表せるとする
  * 保管の仕組み（どこら辺にどの服があるのか）が分かれば、座標（保管されている場所）を指定して新たに服を生成することができる
* 生成AIとして用いる場合は、エンコードの入力とデコードの出力が完全に一致する必要はない。
* オートエンコードの説明
  * デコーダーを含む
* オートエンコーダの課題
  * エンコードの出力値の範囲がまばらであること
  * 値に連続性が無い
* 変分オートエンコーダを使うことでオートエンコーダより再現率が高まる
  * エンコードした値は正規分布に従うため、ある一定の範囲に連続して値が存在しやすい

### 敵対的生成ネットワーク

* 生成器と識別器に競わせながら、生成器の精度の向上を図る
* レンガを使った例がわかりやすかった。そこまで面白い例ではない。
* 識別器が優れすぎていると破綻する
  * 起きやすい事例
* 双方のバランスが大事


### 自己回帰モデル

* 文章の作成に向いている
* 小説を囚人に作らせる例が面白いと思った
  * 現時点での理解度は30%程度


### 正規化フローモデル

* イントロの物語がわかりやすい
* 可逆変換関数を使う
  * エンコーダ写像関数とデコーダ写像関数が可逆的である
* 変数変換の数式は理解しやすかった
* RealNVP
  * カップリング層
  * いまいち理解できなかった
* キーワード
  * 正規化フローモデル
    * RealNVP
    * GLOW
    * FFJORD

### エネルギーベースモデル

* イントロの物語がわかりにくい
* 意味不明
  * EBMの定式化法
  * コントラスティブダイバージェンス
  * ランジュバン動力学

### 拡散モデル

* 「拡散モデル」という言葉に聞き覚えあり

