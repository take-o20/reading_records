# 畳み込みニューラルネットワーク

```python
# Conv2D
# Parameter number: (kernel_size_x * kernel_size_y * input_channel_number + 1) * filter_number
#   kernel_size=(kernel_size_x, kernel_size_y)
#   input_channel_number : input channel number  like rgb means 3
#   filter_number :filter number
# Output shape: (height_size/strides, width_size/strides, filters )
#   height_size: input image height size
#   width_size: input image width size
#   strides: count of stride
#   filters: count of filter

x = layers.Conv2D(filters=32, kernel_size=3, strides=1, padding="same")(
    input_layer
)
# next parameter number: kernel_size=(3,3), input channel is 3, filters is 32, should be (3*3*3+1)*32 = 896
# output shape: input image height is 32, width is 32, strides is 1, and filters is 32, should be (32, 32, 32)
x = layers.BatchNormalization()(x)
# next parameter number: filters is 32, it exist (scale,shift)=(32, 32), should be  (32*2) * 2 = 128
# output shape: (32, 32, 32)
x = layers.LeakyReLU()(x)
# parameter number is 0, because role of activation function is making output non-liner
# output shape: (32, 32, 32) equal to input
```

## 畳み込み層

* フィルターを通してパラメータを畳み込む役割

## バッチ正規化

* スケール、シフトの2つの観点で入力の値を正規化する
* パラメータ数はスケール、シフトを足した値を2倍したもの
  * 4次元の観点から計算を行うため

## 活性化関数

* 入力値を非線形化する役割
* 学習対象のパラメータは0
* 出力のテンソルは入力と同じ

